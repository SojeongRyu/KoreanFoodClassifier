comment: data_not_clean
model and loss plot -> ./model/model_data_not_clean
Namespace(batch_size=100, beta1=0.5, beta2=0.999, comment='data_not_clean', dataroot_dir='./data_not_clean', epoch=30, gpu_mode=True, lr=0.0002, num_workers=4, result_dir='./results/', sample_num=64, save_dir='./model/', type='train')
[*] Training started
[E000]	loss: 2.343172
[E001]	loss: 1.861417
[E002]	loss: 1.959676
[E003]	loss: 2.145615
[E004]	loss: 1.528501
[E005]	loss: 1.553520
[E006]	loss: 1.439873
[E007]	loss: 1.119235
[E008]	loss: 1.191469
[E009]	loss: 1.087667
[E010]	loss: 0.939625
[E011]	loss: 0.824791
[E012]	loss: 1.028872
[E013]	loss: 0.924144
[E014]	loss: 0.748717
[E015]	loss: 0.659488
[E016]	loss: 0.699489
[E017]	loss: 0.450491
[E018]	loss: 0.745984
[E019]	loss: 0.362467
[E020]	loss: 0.366154
[E021]	loss: 0.439509
[E022]	loss: 0.387931
[E023]	loss: 0.367939
[E024]	loss: 0.506781
[E025]	loss: 0.343232
[E026]	loss: 0.345467
[E027]	loss: 0.368431
[E028]	loss: 0.350056
[E029]	loss: 0.374865
Training finished!... save training results
Total time: 947.5071158409119
Per epoch time: [116.01735210418701, 28.226857900619507, 26.488378047943115, 28.52197813987732, 27.763594150543213, 26.366362810134888, 27.735321760177612, 27.001242637634277, 27.66935420036316, 26.474987268447876, 26.07868266105652, 26.653050661087036, 26.176891565322876, 26.098026514053345, 26.782506465911865, 26.74233055114746, 28.17924213409424, 27.588502645492554, 27.286442279815674, 26.374298334121704, 26.532522678375244, 27.61429762840271, 26.707114458084106, 26.151594400405884, 28.069626808166504, 28.26901888847351, 26.10745072364807, 28.833465814590454, 27.49525809288025, 26.179370641708374]
[*] Training finished
