comment: data_clean
model and loss plot -> ./model/model_data_clean
Namespace(batch_size=100, beta1=0.5, beta2=0.999, comment='data_clean', dataroot_dir='./data_clean', epoch=30, gpu_mode=True, lr=0.0002, num_workers=4, result_dir='./results/', sample_num=64, save_dir='./model/', type='train')
[*] Training started
[E000]	loss: 2.329804
[E001]	loss: 2.100229
[E002]	loss: 1.640647
[E003]	loss: 1.266651
[E004]	loss: 1.252543
[E005]	loss: 0.999508
[E006]	loss: 1.088025
[E007]	loss: 1.071693
[E008]	loss: 0.977383
[E009]	loss: 1.112577
[E010]	loss: 0.757990
[E011]	loss: 0.645711
[E012]	loss: 0.892545
[E013]	loss: 0.515842
[E014]	loss: 0.629078
[E015]	loss: 0.505462
[E016]	loss: 0.582244
[E017]	loss: 0.313202
[E018]	loss: 0.535518
[E019]	loss: 0.315769
[E020]	loss: 0.221536
[E021]	loss: 0.488767
[E022]	loss: 0.681849
[E023]	loss: 0.493513
[E024]	loss: 0.194358
[E025]	loss: 0.301986
[E026]	loss: 0.190736
[E027]	loss: 0.218207
[E028]	loss: 0.292192
[E029]	loss: 0.262901
Training finished!... save training results
Total time: 641.4280591011047
Per epoch time: [75.74017596244812, 18.884699821472168, 18.031580209732056, 17.379339933395386, 18.485915899276733, 17.531612157821655, 17.89170789718628, 17.85054039955139, 17.61593198776245, 18.534523487091064, 18.01769208908081, 17.340652465820312, 17.842604160308838, 18.09506869316101, 18.27213978767395, 17.24046039581299, 18.825181007385254, 18.5662682056427, 18.718539714813232, 17.59807586669922, 18.353981018066406, 18.325212001800537, 18.008268356323242, 18.856428384780884, 17.27964472770691, 18.98737144470215, 18.887675762176514, 17.83317995071411, 18.578171968460083, 17.618412256240845]
[*] Training finished
